{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-20 13:39:11.058321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# This file provide template to download the TinyImageNet dataset and then sample code to profile: single, online and batch inference\n",
    "\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# Disable GPU!!!\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Should print the tf version: 2.4.1.\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard_plugin_profile in /usr/local/anaconda3/envs/cpre482x_tf_gpu/lib/python3.9/site-packages (2.5.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/anaconda3/envs/cpre482x_tf_gpu/lib/python3.9/site-packages (from tensorboard_plugin_profile) (3.17.2)\n",
      "Requirement already satisfied: gviz-api>=1.9.0 in /usr/local/anaconda3/envs/cpre482x_tf_gpu/lib/python3.9/site-packages (from tensorboard_plugin_profile) (1.9.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/anaconda3/envs/cpre482x_tf_gpu/lib/python3.9/site-packages (from tensorboard_plugin_profile) (52.0.0.post20210125)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/anaconda3/envs/cpre482x_tf_gpu/lib/python3.9/site-packages (from tensorboard_plugin_profile) (1.16.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/anaconda3/envs/cpre482x_tf_gpu/lib/python3.9/site-packages (from tensorboard_plugin_profile) (1.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Installs the latest tensorboard plugin\n",
    "!pip install -U tensorboard_plugin_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProfilerOptions(host_tracer_level=1, python_tracer_level=0, device_tracer_level=1, delay_ms=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set host level to highest priority for profiling\n",
    "tf.profiler.experimental.ProfilerOptions(\n",
    "    host_tracer_level=1, python_tracer_level=0, device_tracer_level=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to load the tiny imagenet data as usual:\n",
    "\n",
    "# Make sure that unzipped tiny-imagenet-200 folder is placed in the current directory\n",
    "#define path to the dataset\n",
    "path = pathlib.Path('/local/tiny-imagenet-200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the wnids to integer labels to words\n",
    "with open(os.path.join(path, 'wnids.txt'), 'r') as f:\n",
    "  wnids = [x.strip() for x in f]\n",
    "\n",
    "\n",
    "# Map wnids to integer labels\n",
    "wnid_to_label = {wnid: i for i, wnid in enumerate(wnids)}\n",
    "label_to_wnid = {v: k for k, v in wnid_to_label.items()}\n",
    "\n",
    "# Use words.txt to get names for each class\n",
    "with open(os.path.join(path, 'words.txt'), 'r') as f:\n",
    "  wnid_to_words = dict(line.split('\\t') for line in f)\n",
    "  for wnid, words in wnid_to_words.items():\n",
    "      wnid_to_words[wnid] = [w.strip() for w in words.split(',')]\n",
    "class_names = [wnid_to_words[wnid] for wnid in wnids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "from __future__ import print_function\n",
    "from builtins import range\n",
    "from six.moves import cPickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import platform\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from imageio import imread\n",
    "from imageio import imsave\n",
    "\n",
    "\n",
    "# Function for loading the tiny imagenet data\n",
    "def load_tiny_imagenet(path, is_training=True, dtype=np.float32, subtract_mean=True, debug=False, debug_nclass=3):\n",
    "    \"\"\"\n",
    "    Load TinyImageNet. Each of TinyImageNet-100-A, TinyImageNet-100-B, and\n",
    "    TinyImageNet-200 have the same directory structure, so this can be used\n",
    "    to load any of them.\n",
    "\n",
    "    Note: The original implementation loaded data as NCHW, I (tyler) changed it to NHWC\n",
    "\n",
    "    Inputs:\n",
    "    - path: String giving path to the directory to load.\n",
    "    - is_training: If True, dont load testing data, if False, dont load training and val data\n",
    "        Note: Must always load training data in order to subtract_mean.\n",
    "    - dtype: numpy datatype used to load the data.\n",
    "    - subtract_mean: Whether to subtract the mean training image.\n",
    "    - debug: Whether or not to load a small number of classes for debugging\n",
    "\n",
    "    Returns: A dictionary with the following entries:\n",
    "    - class_names: A list where class_names[i] is a list of strings giving the\n",
    "      WordNet names for class i in the loaded dataset.\n",
    "    - X_train: (N_tr, 64, 64, 3) array of training images\n",
    "    - y_train: (N_tr,) array of training labels\n",
    "    - X_val: (N_val, 64, 64, 3) array of validation images\n",
    "    - y_val: (N_val,) array of validation labels\n",
    "    - X_test: (N_test, 64, 64, 3) array of testing images.\n",
    "    - y_test: (N_test,) array of test labels; if test labels are not available\n",
    "      (such as in student code) then y_test will be None.\n",
    "    - mean_image: (64, 64, 3) array giving mean training image\n",
    "    - label_to_wnid: dictionary with mapping from integer class label to wnid\n",
    "    \"\"\"\n",
    "    # First load wnids\n",
    "    with open(os.path.join(path, 'wnids.txt'), 'r') as f:\n",
    "        wnids = [x.strip() for x in f]\n",
    "\n",
    "    # Map wnids to integer labels\n",
    "    wnid_to_label = {wnid: i for i, wnid in enumerate(wnids)}\n",
    "    label_to_wnid = {v: k for k, v in wnid_to_label.items()}\n",
    "\n",
    "    # Use words.txt to get names for each class\n",
    "    with open(os.path.join(path, 'words.txt'), 'r') as f:\n",
    "        wnid_to_words = dict(line.split('\\t') for line in f)\n",
    "        for wnid, words in wnid_to_words.items():\n",
    "            wnid_to_words[wnid] = [w.strip() for w in words.split(',')]\n",
    "    class_names = [wnid_to_words[wnid] for wnid in wnids]\n",
    "\n",
    "    if debug:\n",
    "        print('Debug is on! Only loading %d / %d training classes.'\n",
    "                  % (debug_nclass, len(wnids)))\n",
    "\n",
    "    # Next load training data.\n",
    "    X_train, y_train = [], []\n",
    "    train_wnids = wnids[:debug_nclass] if debug else wnids\n",
    "    for i, wnid in tqdm(enumerate(train_wnids), total=len(train_wnids)):\n",
    "        # To figure out the filenames we need to open the boxes file\n",
    "        boxes_file = os.path.join(path, 'train', wnid, '%s_boxes.txt' % wnid)\n",
    "        with open(boxes_file, 'r') as f:\n",
    "            filenames = [x.split('\\t')[0] for x in f]\n",
    "        num_images = len(filenames)\n",
    "\n",
    "        X_train_block = np.zeros((num_images, 64, 64, 3), dtype=dtype)\n",
    "        y_train_block = wnid_to_label[wnid] * \\\n",
    "                        np.ones(num_images, dtype=np.int64)\n",
    "        for j, img_file in enumerate(filenames):\n",
    "            img_file = os.path.join(path, 'train', wnid, 'images', img_file)\n",
    "            img = imread(img_file)\n",
    "            if img.ndim == 2:   ## grayscale file\n",
    "                img.shape = (64, 64, 1)\n",
    "            X_train_block[j] = img\n",
    "        X_train.append(X_train_block)\n",
    "        y_train.append(y_train_block)\n",
    "\n",
    "    # We need to concatenate all training data\n",
    "    X_train = np.concatenate(X_train, axis=0)\n",
    "    y_train = np.concatenate(y_train, axis=0)\n",
    "\n",
    "    # Next load validation data\n",
    "    X_val, y_val = None, None\n",
    "    if is_training:\n",
    "        print('loading validation data')\n",
    "        with open(os.path.join(path, 'val', 'val_annotations.txt'), 'r') as f:\n",
    "            img_files = []\n",
    "            val_wnids = []\n",
    "            for line in f:\n",
    "                img_file, wnid = line.split('\\t')[:2]\n",
    "                img_files.append(img_file)\n",
    "                val_wnids.append(wnid)\n",
    "            num_val = len(img_files)\n",
    "            y_val = np.array([wnid_to_label[wnid] for wnid in val_wnids])\n",
    "            X_val = np.zeros((num_val, 64, 64, 3), dtype=dtype)\n",
    "            for i, img_file in tqdm(enumerate(img_files), total=len(img_files)):\n",
    "                img_file = os.path.join(path, 'val', 'images', img_file)\n",
    "                img = imread(img_file)\n",
    "                if img.ndim == 2:\n",
    "                    img.shape = (64, 64, 1)\n",
    "                X_val[i] = img\n",
    "\n",
    "    mean_image = None\n",
    "    if subtract_mean:\n",
    "        mean_image = X_train.mean(axis=0)\n",
    "        if is_training:\n",
    "            X_train -= mean_image[None]\n",
    "            X_val -= mean_image[None]\n",
    "        else:\n",
    "            X_test -= mean_image[None]\n",
    "\n",
    "    if not is_training:\n",
    "        X_train = None\n",
    "        y_train = None\n",
    "\n",
    "    return {\n",
    "      'class_names': class_names,\n",
    "      'X_train': X_train,\n",
    "      'y_train': y_train,\n",
    "      'X_val': X_val,\n",
    "      'y_val': y_val,\n",
    "      'mean_image': mean_image,\n",
    "      'label_to_wnid': label_to_wnid\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Tiny-Imagenet Dataset for training and validation data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:39<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading validation data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:03<00:00, 2568.54it/s]\n"
     ]
    }
   ],
   "source": [
    "print (\"Loading Tiny-Imagenet Dataset for training and validation data\")\n",
    "dataset_train_val = load_tiny_imagenet(path, is_training = True, dtype=np.float32, subtract_mean=False)\n",
    "x_val = dataset_train_val[\"X_val\"] # 10000 images when each is a 64*64*3\n",
    "y_val = dataset_train_val[\"y_val\"] # 10000 elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all the float data between 0 and 1\n",
    "x_val = x_val/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode y data\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "num_classes = 200\n",
    "y_val = to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-20 13:39:58.909756: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-09-20 13:39:58.911036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-09-20 13:39:58.928354: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-09-20 13:39:58.928418: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: cpre482-03.ece.iastate.edu\n",
      "2021-09-20 13:39:58.928429: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: cpre482-03.ece.iastate.edu\n",
      "2021-09-20 13:39:58.928571: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.63.1\n",
      "2021-09-20 13:39:58.928620: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.63.1\n",
      "2021-09-20 13:39:58.928628: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 470.63.1\n",
      "2021-09-20 13:39:58.929153: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-20 13:39:58.929477: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "# To do:  Load the H5 model and print summary. \n",
    "# Please make sure the h5 model file is present in the /local/ directory\n",
    "# Sample code to load the model\n",
    "model = tf.keras.models.load_model('/local/CNN_TinyImageNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-20 13:48:08.075516: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-09-20 13:48:08.075550: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-09-20 13:48:08.087017: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2021-09-20 13:48:08.087954: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-09-20 13:48:08.092286: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134808/plugins/profile/2021_09_20_13_48_08\n",
      "2021-09-20 13:48:08.093054: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134808/plugins/profile/2021_09_20_13_48_08/cpre482-03.ece.iastate.edu.trace.json.gz\n",
      "2021-09-20 13:48:08.093806: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134808/plugins/profile/2021_09_20_13_48_08\n",
      "2021-09-20 13:48:08.093895: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134808/plugins/profile/2021_09_20_13_48_08/cpre482-03.ece.iastate.edu.memory_profile.json.gz\n",
      "2021-09-20 13:48:08.094092: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134808/plugins/profile/2021_09_20_13_48_08Dumped tool data for xplane.pb to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134808/plugins/profile/2021_09_20_13_48_08/cpre482-03.ece.iastate.edu.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134808/plugins/profile/2021_09_20_13_48_08/cpre482-03.ece.iastate.edu.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134808/plugins/profile/2021_09_20_13_48_08/cpre482-03.ece.iastate.edu.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134808/plugins/profile/2021_09_20_13_48_08/cpre482-03.ece.iastate.edu.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134808/plugins/profile/2021_09_20_13_48_08/cpre482-03.ece.iastate.edu.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 11097), started 0:08:06 ago. (Use '!kill 11097' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9f3b3529d35e94ef\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9f3b3529d35e94ef\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample Profiling: Inference for a single image:\n",
    "\n",
    "# chose any desired image between 0 and 9999 (10,000 validation set images)\n",
    "image_index=0\n",
    "\n",
    "# load the data\n",
    "val_single_image = tf.data.Dataset.from_tensors(x_val[image_index].reshape(1,64,64,3)) \n",
    "\n",
    "\n",
    "logs=\"/local/Lab2/Tensorboard/Template_Profiling/logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "\n",
    "# Perform the inference profiling:\n",
    "\n",
    "# Starts Profile logging\n",
    "tf.profiler.experimental.start(logs)\n",
    "\n",
    "# Actual inference\n",
    "model.predict(val_single_image, use_multiprocessing=True)\n",
    "\n",
    "# Stops Profile logging\n",
    "tf.profiler.experimental.stop()\n",
    "\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Launch TensorBoard and navigate to the Profile tab to view performance profile. \n",
    "# *** Please note just execute this command ones in a session and \n",
    "# then logs for subsequent runs would be auto detected in tensorboard- url: http://localhost:6006/\n",
    "%tensorboard --logdir=logs\n",
    "\n",
    "# You could view the tensorboard in the browser url: http://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-20 13:49:02.728534: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-09-20 13:49:02.728569: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-09-20 13:49:12.303700: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2021-09-20 13:49:13.079509: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-09-20 13:49:13.960852: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134902/plugins/profile/2021_09_20_13_49_13\n",
      "2021-09-20 13:49:14.688389: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134902/plugins/profile/2021_09_20_13_49_13/cpre482-03.ece.iastate.edu.trace.json.gz\n",
      "2021-09-20 13:49:14.944754: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134902/plugins/profile/2021_09_20_13_49_13\n",
      "2021-09-20 13:49:14.944899: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134902/plugins/profile/2021_09_20_13_49_13/cpre482-03.ece.iastate.edu.memory_profile.json.gz\n",
      "2021-09-20 13:49:14.952348: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134902/plugins/profile/2021_09_20_13_49_13Dumped tool data for xplane.pb to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134902/plugins/profile/2021_09_20_13_49_13/cpre482-03.ece.iastate.edu.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134902/plugins/profile/2021_09_20_13_49_13/cpre482-03.ece.iastate.edu.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134902/plugins/profile/2021_09_20_13_49_13/cpre482-03.ece.iastate.edu.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134902/plugins/profile/2021_09_20_13_49_13/cpre482-03.ece.iastate.edu.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134902/plugins/profile/2021_09_20_13_49_13/cpre482-03.ece.iastate.edu.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 11097), started 0:09:13 ago. (Use '!kill 11097' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6bfe8b6776804a14\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6bfe8b6776804a14\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample Profiling: Online Inference:\n",
    "\n",
    "# Vary this from 10, 100, 1000 to simulate multiple online inference\n",
    "loop_index=1000 \n",
    "\n",
    "logs=\"/local/Lab2/Tensorboard/Template_Profiling/logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "\n",
    "# Starts Profile logging\n",
    "tf.profiler.experimental.start(logs)\n",
    "\n",
    "# Actual online inference\n",
    "for i in range(loop_index):\n",
    "    dataset=tf.data.Dataset.from_tensors(x_val[i].reshape(1,64,64,3))\n",
    "    model.predict(dataset,use_multiprocessing=True)\n",
    "\n",
    "# Stops Profile logging\n",
    "tf.profiler.experimental.stop()\n",
    "\n",
    "# You could view the tensorboard in the browser url: vand then in the profile tab navigate to the latest run.\n",
    "\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Launch TensorBoard and navigate to the Profile tab to view performance profile. \n",
    "# *** Please note just execute this command ones in a session and \n",
    "# then logs for subsequent runs would be auto detected in tensorboard- url: http://localhost:6006/\n",
    "%tensorboard --logdir=logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-20 13:49:53.698483: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-09-20 13:49:53.698515: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-09-20 13:49:53.756841: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 460800000 exceeds 10% of free system memory.\n",
      "2021-09-20 13:49:55.108815: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2021-09-20 13:49:55.109816: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-09-20 13:49:55.111149: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134953/plugins/profile/2021_09_20_13_49_55\n",
      "2021-09-20 13:49:55.111944: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134953/plugins/profile/2021_09_20_13_49_55/cpre482-03.ece.iastate.edu.trace.json.gz\n",
      "2021-09-20 13:49:55.112757: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134953/plugins/profile/2021_09_20_13_49_55\n",
      "2021-09-20 13:49:55.112870: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134953/plugins/profile/2021_09_20_13_49_55/cpre482-03.ece.iastate.edu.memory_profile.json.gz\n",
      "2021-09-20 13:49:55.113068: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134953/plugins/profile/2021_09_20_13_49_55Dumped tool data for xplane.pb to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134953/plugins/profile/2021_09_20_13_49_55/cpre482-03.ece.iastate.edu.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134953/plugins/profile/2021_09_20_13_49_55/cpre482-03.ece.iastate.edu.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134953/plugins/profile/2021_09_20_13_49_55/cpre482-03.ece.iastate.edu.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134953/plugins/profile/2021_09_20_13_49_55/cpre482-03.ece.iastate.edu.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /local/Lab2/Tensorboard/Template_Profiling/logs/20210920-134953/plugins/profile/2021_09_20_13_49_55/cpre482-03.ece.iastate.edu.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 11097), started 0:09:53 ago. (Use '!kill 11097' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-818cc1637b0f953e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-818cc1637b0f953e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample Profiling: Batch Inference:\n",
    "\n",
    "# We would only perform batch inference for a subset of validation set i.e. 1000 images \n",
    "# using different batch sizes of 20, 40, 100, 200 \n",
    "\n",
    "# Decides the size of the batch. Try: 20, 40, 100, 200\n",
    "Size_Batch= 20 \n",
    "\n",
    "logs=\"/local/Lab2/Tensorboard/Template_Profiling/logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "\n",
    "# Starts Profile logging\n",
    "tf.profiler.experimental.start(logs)\n",
    "\n",
    "# Actual Batch inference\n",
    "dataset=tf.data.Dataset.from_tensors(x_val[0:1000,:,:,:])\n",
    "model.predict(dataset,batch_size=Size_Batch, use_multiprocessing=True)\n",
    "\n",
    "# Stops Profile logging\n",
    "tf.profiler.experimental.stop()\n",
    "\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Launch TensorBoard and navigate to the Profile tab to view performance profile. \n",
    "# *** Please note just execute this command ones in a session and \n",
    "# then logs for subsequent runs would be auto detected in tensorboard- url: http://localhost:6006/\n",
    "%tensorboard --logdir=logs\n",
    "\n",
    "# You could view the tensorboard in the browser url: http://localhost:6006/ and then in the profile tab navigate to the latest run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
