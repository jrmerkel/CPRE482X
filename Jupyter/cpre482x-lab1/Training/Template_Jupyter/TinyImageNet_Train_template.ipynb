{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWQY7_ZTP5aH"
   },
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 18:55:46.805276: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 18:55:48.781181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-09-18 18:55:48.801679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-18 18:55:48.801949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:02:02.0 name: GRID RTX8000-2Q computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2021-09-18 18:55:48.801970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-18 18:55:48.848917: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-09-18 18:55:48.848978: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-09-18 18:55:48.870978: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-18 18:55:48.911263: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-18 18:55:48.953257: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-18 18:55:48.972169: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-09-18 18:55:49.055325: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-09-18 18:55:49.055495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-18 18:55:49.055813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-18 18:55:49.056019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "print(tf.__version__)\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Enable or disable GPU\n",
    "# ENABLE_GPU = False\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "# print(\"TensorFlow version: \", tf.__version__)\n",
    "# devices = tf.config.list_physical_devices(device_type=None)\n",
    "# if not ENABLE_GPU:\n",
    "#     tf.config.set_visible_devices([], 'GPU')\n",
    "# device_name = tf.test.gpu_device_name()\n",
    "# if not device_name:\n",
    "#     print('Running on CPU')\n",
    "# else:\n",
    "#     print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrz63rys1qNr"
   },
   "outputs": [],
   "source": [
    "#define path to the dataset\n",
    "path = pathlib.Path('/local/tiny-imagenet-200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kAw5faJHQT03"
   },
   "outputs": [],
   "source": [
    "# First load wnids\n",
    "with open(os.path.join(path, 'wnids.txt'), 'r') as f:\n",
    "  wnids = [x.strip() for x in f]\n",
    "\n",
    "# Map wnids to integer labels\n",
    "wnid_to_label = {wnid: i for i, wnid in enumerate(wnids)}\n",
    "label_to_wnid = {v: k for k, v in wnid_to_label.items()}\n",
    "\n",
    "\n",
    "# Use words.txt to get names for each class\n",
    "with open(os.path.join(path, 'words.txt'), 'r') as f:\n",
    "  wnid_to_words = dict(line.split('\\t') for line in f)\n",
    "  for wnid, words in wnid_to_words.items():\n",
    "      wnid_to_words[wnid] = [w.strip() for w in words.split(',')]\n",
    "class_names = [wnid_to_words[wnid] for wnid in wnids]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z_5SvXQF0Tz6"
   },
   "outputs": [],
   "source": [
    "# Function to load training and validation data\n",
    "\n",
    "# Import necessary packages\n",
    "from __future__ import print_function\n",
    "from builtins import range\n",
    "from six.moves import cPickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import platform\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from imageio import imread\n",
    "from imageio import imsave\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function for loading the tiny imagenet data\n",
    "def load_tiny_imagenet(path, is_training=True, dtype=np.float32, subtract_mean=True, debug=False, debug_nclass=3):\n",
    "    \"\"\"\n",
    "    Load TinyImageNet. Each of TinyImageNet-100-A, TinyImageNet-100-B, and\n",
    "    TinyImageNet-200 have the same directory structure, so this can be used\n",
    "    to load any of them.\n",
    "\n",
    "    Note: The original implementation loaded data as NCHW, I (tyler) changed it to NHWC\n",
    "\n",
    "    Inputs:\n",
    "    - path: String giving path to the directory to load.\n",
    "    - is_training: If True, dont load testing data, if False, dont load training and val data\n",
    "        Note: Must always load training data in order to subtract_mean.\n",
    "    - dtype: numpy datatype used to load the data.\n",
    "    - subtract_mean: Whether to subtract the mean training image.\n",
    "    - debug: Whether or not to load a small number of classes for debugging\n",
    "\n",
    "    Returns: A dictionary with the following entries:\n",
    "    - class_names: A list where class_names[i] is a list of strings giving the\n",
    "      WordNet names for class i in the loaded dataset.\n",
    "    - X_train: (N_tr, 64, 64, 3) array of training images\n",
    "    - y_train: (N_tr,) array of training labels\n",
    "    - X_val: (N_val, 64, 64, 3) array of validation images\n",
    "    - y_val: (N_val,) array of validation labels\n",
    "    - X_test: (N_test, 64, 64, 3) array of testing images.\n",
    "    - y_test: (N_test,) array of test labels; if test labels are not available\n",
    "      (such as in student code) then y_test will be None.\n",
    "    - mean_image: (64, 64, 3) array giving mean training image\n",
    "    - label_to_wnid: dictionary with mapping from integer class label to wnid\n",
    "    \"\"\"\n",
    "    # First load wnids\n",
    "    with open(os.path.join(path, 'wnids.txt'), 'r') as f:\n",
    "        wnids = [x.strip() for x in f]\n",
    "\n",
    "    # Map wnids to integer labels\n",
    "    wnid_to_label = {wnid: i for i, wnid in enumerate(wnids)}\n",
    "    label_to_wnid = {v: k for k, v in wnid_to_label.items()}\n",
    "\n",
    "    # Use words.txt to get names for each class\n",
    "    with open(os.path.join(path, 'words.txt'), 'r') as f:\n",
    "        wnid_to_words = dict(line.split('\\t') for line in f)\n",
    "        for wnid, words in wnid_to_words.items():\n",
    "            wnid_to_words[wnid] = [w.strip() for w in words.split(',')]\n",
    "    class_names = [wnid_to_words[wnid] for wnid in wnids]\n",
    "\n",
    "    if debug:\n",
    "        print('Debug is on! Only loading %d / %d training classes.'\n",
    "                  % (debug_nclass, len(wnids)))\n",
    "\n",
    "    # Next load training data.\n",
    "    X_train, y_train = [], []\n",
    "    train_wnids = wnids[:debug_nclass] if debug else wnids\n",
    "    for i, wnid in tqdm(enumerate(train_wnids), total=len(train_wnids)):\n",
    "        # To figure out the filenames we need to open the boxes file\n",
    "        boxes_file = os.path.join(path, 'train', wnid, '%s_boxes.txt' % wnid)\n",
    "        with open(boxes_file, 'r') as f:\n",
    "            filenames = [x.split('\\t')[0] for x in f]\n",
    "        num_images = len(filenames)\n",
    "\n",
    "        X_train_block = np.zeros((num_images, 64, 64, 3), dtype=dtype)\n",
    "        y_train_block = wnid_to_label[wnid] * \\\n",
    "                        np.ones(num_images, dtype=np.int64)\n",
    "        for j, img_file in enumerate(filenames):\n",
    "            img_file = os.path.join(path, 'train', wnid, 'images', img_file)\n",
    "            img = imread(img_file)\n",
    "            if img.ndim == 2:   ## grayscale file\n",
    "                img.shape = (64, 64, 1)\n",
    "            X_train_block[j] = img\n",
    "        X_train.append(X_train_block)\n",
    "        y_train.append(y_train_block)\n",
    "\n",
    "    # We need to concatenate all training data\n",
    "    X_train = np.concatenate(X_train, axis=0)\n",
    "    y_train = np.concatenate(y_train, axis=0)\n",
    "\n",
    "    # Next load validation data\n",
    "    X_val, y_val = None, None\n",
    "    if is_training:\n",
    "        print('loading validation data')\n",
    "        with open(os.path.join(path, 'val', 'val_annotations.txt'), 'r') as f:\n",
    "            img_files = []\n",
    "            val_wnids = []\n",
    "            for line in f:\n",
    "                img_file, wnid = line.split('\\t')[:2]\n",
    "                img_files.append(img_file)\n",
    "                val_wnids.append(wnid)\n",
    "            num_val = len(img_files)\n",
    "            y_val = np.array([wnid_to_label[wnid] for wnid in val_wnids])\n",
    "            X_val = np.zeros((num_val, 64, 64, 3), dtype=dtype)\n",
    "            for i, img_file in tqdm(enumerate(img_files), total=len(img_files)):\n",
    "                img_file = os.path.join(path, 'val', 'images', img_file)\n",
    "                img = imread(img_file)\n",
    "                if img.ndim == 2:\n",
    "                    img.shape = (64, 64, 1)\n",
    "                X_val[i] = img\n",
    "\n",
    "    mean_image = None\n",
    "    if subtract_mean:\n",
    "        mean_image = X_train.mean(axis=0)\n",
    "        if is_training:\n",
    "            X_train -= mean_image[None]\n",
    "            X_val -= mean_image[None]\n",
    "        else:\n",
    "            X_test -= mean_image[None]\n",
    "\n",
    "    if not is_training:\n",
    "        X_train = None\n",
    "        y_train = None\n",
    "\n",
    "    return {\n",
    "      'class_names': class_names,\n",
    "      'X_train': X_train,\n",
    "      'y_train': y_train,\n",
    "      'X_val': X_val,\n",
    "      'y_val': y_val,\n",
    "      'mean_image': mean_image,\n",
    "      'label_to_wnid': label_to_wnid\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "id": "eZJ9EQPH2XF0",
    "outputId": "2459b192-8943-4281-f284-6879d56c15f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Tiny-Imagenet Dataset for training and validation data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [01:08<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading validation data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10000/10000 [00:07<00:00, 1325.94it/s]\n"
     ]
    }
   ],
   "source": [
    "print (\"Loading Tiny-Imagenet Dataset for training and validation data\")\n",
    "dataset_train_val = load_tiny_imagenet(path, is_training = True, dtype=np.float32, subtract_mean=False)\n",
    "x_train = dataset_train_val[\"X_train\"] # 100000 images when each is a 64*64*3\n",
    "y_train = dataset_train_val[\"y_train\"] # 100000 elements\n",
    "#slice those suckers down\n",
    "x_train = x_train[1:50000]\n",
    "y_train = y_train[1:50000]\n",
    "x_val = dataset_train_val[\"X_val\"] # 10000 images when each is a 64*64*3\n",
    "y_val = dataset_train_val[\"y_val\"] # 10000 elements\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mKiramsCwe8h"
   },
   "outputs": [],
   "source": [
    "x_train=x_train/255.0\n",
    "x_val=x_val/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-D7Vn0oEKbwl"
   },
   "outputs": [],
   "source": [
    "# # one hot encode y data\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# num_classes = 200\n",
    "# y_train = to_categorical(y_train, num_classes)\n",
    "# y_val = to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBJA8zevI5Yb"
   },
   "outputs": [],
   "source": [
    "# Import required packages for training\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, ZeroPadding2D,Convolution2D, Activation, Dropout \n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "\n",
    "#from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "colab_type": "code",
    "id": "iUawHlDUOK97",
    "outputId": "47d1bf1b-e36d-43cc-fadc-9552bb696335"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 18:57:08.389135: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-18 18:57:08.398173: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2294605000 Hz\n",
      "2021-09-18 18:57:08.398869: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ea9765c6b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-09-18 18:57:08.398893: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-09-18 18:57:08.399204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-18 18:57:08.399536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:02:02.0 name: GRID RTX8000-2Q computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2021-09-18 18:57:08.399580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-18 18:57:08.399608: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-09-18 18:57:08.399620: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-09-18 18:57:08.399631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-18 18:57:08.399643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-18 18:57:08.399654: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-18 18:57:08.399665: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-09-18 18:57:08.399677: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-09-18 18:57:08.399770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-18 18:57:08.400029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-18 18:57:08.400219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-09-18 18:57:08.400254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-18 18:57:09.916039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-18 18:57:09.916079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-09-18 18:57:09.916092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-09-18 18:57:09.916445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-18 18:57:09.916816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-18 18:57:09.917114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-18 18:57:09.917315: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-09-18 18:57:09.917364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 497 MB memory) -> physical GPU (device: 0, name: GRID RTX8000-2Q, pci bus id: 0000:02:02.0, compute capability: 7.5)\n",
      "2021-09-18 18:57:09.929249: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55eaaa27f690 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-09-18 18:57:09.929275: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GRID RTX8000-2Q, Compute Capability 7.5\n"
     ]
    }
   ],
   "source": [
    "# Basic CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# conv1\n",
    "model.add(Conv2D(32, (5, 5), input_shape= (64, 64, 3),activation='relu'))\n",
    "model.add(Conv2D(32,(5,5),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "# fc1\n",
    "model.add(Dense(256,activation='relu'))\n",
    "\n",
    "# fc2\n",
    "model.add(Dense(200,activation='softmax'))\n",
    "\n",
    "# sgd = SGD(lr=0.01, momentum=0.9)\n",
    "#model.compile(loss='categorical_crossentropy' ,optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#model.compile(loss='sparse_categorical_crossentropy' ,optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "            tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name='Top5'),\n",
    "            tf.keras.metrics.SparseTopKCategoricalAccuracy(k=1, name='Top1')],\n",
    ")\n",
    "\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "2qR-UdvFKDI7",
    "outputId": "b2cd11a5-6e41-44be-f540-de742af1fa69"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 18:57:10.068709: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2457550848 exceeds 10% of free system memory.\n",
      "2021-09-18 18:57:12.005426: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 18:57:12.592799: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-09-18 18:57:13.116745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-09-18 18:57:15.803189: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2021-09-18 18:57:15.916202: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2021-09-18 18:57:17.442917: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:17.443058: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 333.70M (349905920 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:17.443091: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 322.25MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-09-18 18:57:17.443253: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:17.443268: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 82.10MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-09-18 18:57:17.443468: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:17.443486: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 37.30MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-09-18 18:57:17.443618: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:17.443633: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 81.36MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-09-18 18:57:19.229963: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:19.230035: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 56.50MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-09-18 18:57:19.230246: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:19.230263: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 67.14MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-09-18 18:57:19.431491: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:19.431559: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 50.02MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-09-18 18:57:20.621784: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:20.621847: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 50.02MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-09-18 18:57:21.829620: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:21.829680: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 75.52MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-09-18 18:57:23.544375: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:23.544446: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 75.52MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-09-18 18:57:24.543108: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:26.316343: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:26.316532: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:26.510365: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:26.896435: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:27.708404: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:28.698434: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:29.296456: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:29.296644: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:29.296797: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:29.296945: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:29.708509: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:29.708663: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:30.312940: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 370.77M (388784128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:30.315083: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2021-09-18 18:57:30.316283: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 386.77M (405561344 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:30.316458: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 386.77M (405561344 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1555/1563 [============================>.] - ETA: 0s - loss: 4.9728 - sparse_categorical_accuracy: 0.0095 - Top5: 0.0513 - Top1: 0.0095"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 18:57:43.662208: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 386.77M (405561344 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:43.662260: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2021-09-18 18:57:43.663728: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 450.77M (472670208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:43.663880: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 450.77M (472670208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:43.663977: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 450.77M (472670208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:43.664060: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 450.77M (472670208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:43.664576: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 450.77M (472670208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-09-18 18:57:43.862481: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 450.77M (472670208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "# Training on the tiny image dataset\n",
    "# Experiment here with the batch size, number of epochs etc as mentioned in the lab1 doc.\n",
    "# model.fit(x_train,y_train, validation_data=(x_val, y_val),batch_size=256,callbacks=callbacks,\n",
    "#           epochs=100)\n",
    "\n",
    "\n",
    "# model.fit(x_train,y_train, validation_data=(x_val, y_val),batch_size=32,\n",
    "#           epochs=15)\n",
    "\n",
    "#model.fit_generator(x_train,y_train, validation_data=(x_val, y_val),batch_size=32,epochs=10)\n",
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = InteractiveSession(config=config)\n",
    "start_time = time.time()\n",
    "\n",
    "# model.fit(x_train,y_train, validation_split=0.3,batch_size=32,\n",
    "#           epochs=15)\n",
    "history = model.fit(x_train,y_train, validation_data=(x_val, y_val),batch_size=32,\n",
    "          epochs=20)\n",
    "\n",
    "\n",
    "print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mhQnvMlaWZ16",
    "outputId": "59b288d6-b1f8-416d-b24d-786af0fab419"
   },
   "outputs": [],
   "source": [
    "# Save the cnn model\n",
    "model.save('CNN_TinyImageNet_trained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x=x_val, y=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 4-1\n",
    "###Batch 32\n",
    "## Top5: 0.4535\n",
    "## Top1: 0.2237\n",
    "\n",
    "#### 4-3\n",
    "## idk if this is right but for 1/4 dataset\n",
    "## Top5: 0.1321\n",
    "## Top1: 0.0586\n",
    "## 1/2 dataset\n",
    "## Top5: 0.0358\n",
    "## Top1: 0.0077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4-2\n",
    "#instead of 3 I just plotted up to 40\n",
    "#a the validation accuracy increased up until a point where it starts to overtrain on the\n",
    "#b Since I was only able to run for 40 epochs since the Jupyter notebooks keep crashing I've spent hours on this already\n",
    "# Top5 0.3596999943256378,\n",
    "# Top1 0.15940000116825104\n",
    "# was the end\n",
    "# somewhere in the middle it peaks around 0.45 for top 5 and 0.224 for top 1\n",
    "#c Like I said in a, the reason the validation accuracy starts going down is you overtrain/overfit for the training dataset so your model\n",
    "# is not generalized enough to work on new inputs (validation data)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(history.history['val_Top1'])\n",
    "plt.plot(history.history['val_Top5'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Top1', 'Top5'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CA7NiZHDJ8WO"
   },
   "outputs": [],
   "source": [
    "# Place the logs in a timestamped subdirectory\n",
    "# This allows to easy select different training runs\n",
    "# In order not to overwrite some data, it is useful to have a name with a timestamp\n",
    "#log_dir=\"C:/Temp/CPRE482X/Lab1/Files/Training/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Specify the callback object\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# tf.keras.callback.TensorBoard ensures that logs are created and stored\n",
    "# We need to pass callback object to the fit method\n",
    "# The way to do this is by passing the list of callback objects, which is in our case just one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qfzVH5hSVZbW",
    "outputId": "66d00118-f4c6-4302-b3b8-6920a9aea5a2"
   },
   "outputs": [],
   "source": [
    "# # Using early stopping to monitor validation accuracy\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.EarlyStopping(\n",
    "#         # Stop training when `val_loss` is no longer improving\n",
    "#         monitor=\"val_loss\",\n",
    "#         # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "#         min_delta=1e-2,\n",
    "#         # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "#         patience=2,\n",
    "#         verbose=1,\n",
    "#     )\n",
    "# #     tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "    \n",
    "# ]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "TinyImagenet_Basic_CNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
